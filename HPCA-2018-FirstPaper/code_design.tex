\section{Codes to Improve Accesses}
\label{sec:code_design}

%In this section, we discuss one of the main components of the memory design proposed in this paper. 
As a key idea behind the memory designs proposed in this paper, we plan to utilize coding schemes to introduce redundancy into the storage space comprising an array of single-port memory banks in order to support multiple accesses to the array. For this approach to be successful, it's important to work with the right coding schemes which are designed by keeping the access-efficiency as the central criterion. 

In this section, we describe coding schemes which are designed with access efficiency as a key criterion. We first define some basic concepts with an illustrative example, and then describe our $3$ schemes in detail.

\begin{comment}
Coding theory is the study of codes and their applications  to specific fields.  
Coding has been used in a variety of computer  science applications,  from error 
correction in the transmission of data  to increased compression for data  
storage.  We aim to extend the benefits of coding theory  to improve the 
efficiency of random-access  memory systems.  We propose a memory scheme in 
which a small portion of memory is reserved for the efficient coding of 
pre-existing data.  In essence, this allows the data of one bank to be 
duplicated and stored in an additional memory location.  Traditionally, when 
multiple  requests  to a single bank  are issued by the processor, a stall is 
generated.  These types of stalls, known as bank conflicts, result from the fact 
that  only one address from a single bank can be accessed at a time.  The 
processor must wait for the result from the first bank access to return  before 
it can serve additional  requests to the same bank.  This lag can be a major 
bottleneck in a computer's processing speed. With a coded memory scheme, data 
present in multiple data banks will be compressed and stored in extra banks, 
known as a parity banks.  These parity banks will then be accessed concurrently 
with corresponding data  banks to help alleviate stalls from bank conflicts.  
Ultimately,  with the addition  of a single parity  bank we are able to generate 
a single additional  access to any arbitrary bank  without  implementing  any 
further  logic to the bank  itself.  In the following sections, we first 
describe the design parameters used to design the coding system.  We then 
describe each of the three code designs explored in this project.
\end{comment}

\subsection{Coding for memory banks}
\label{sec:coding_mb}

A coding scheme is defined by its encoding process which maps a given collection of information elements to a larger and redundant collection of elements known as codeword. In the context of memory banks, we begin with {\em data banks} which refer to the memory bank storing the original information. The encoding process of the underlying coding scheme then utilize the content of these data banks to generate elements to be stored in the additional memory banks such the overall array of memory banks stores the information in a redundant manner. The additional memory banks are termed as {\em parity banks}. The encoding operations used to generate parity elements in this paper can be classified into two categories.
\begin{enumerate}
\item \textbf{Inter-bank encoding:~}A parity element depends on at most one element for each of the data banks.
\item \textbf{Intra-bank encoding:~}A parity element is generated using multiple elements from a data bank.
\end{enumerate}
Furthermore, we restrict ourselves to linear coding schemes which perform only linear operations (over a finite field) during the encoding process. In fact, in order to keep the computation complexity small, we only consider coding schemes over the binary field. This implies that the linear operations are nothing but XOR operations. \Ethan{rewrite?} %This is equivalent to saying that the elements stored on the parity banks are linear functions of the elements stored on the data banks. 
The following example further clarifies these concepts along with some necessary notation with help of a coding scheme that employs only {inter-bank} encoding. 
\begin{example}
Consider a setup with two data banks $\mathbf{a}$ and $\mathbf{b}$. We assume that each of banks store $L \cdot W$ binary data elements\footnote{It is possible to work with data elements over larger alphabets/finite fields. However, assuming data elements to be binary suffices for us as we only work with coding schemes defined over binary field in this paper.} which are arranged in an $L \times W$ array. In particular, for $i \in [L] \triangleq \{1,\ldots, L\}$, $a(i)$ and $b(i)$ denote the $i$-th row of the bank $\mathbf{a}$ and bank $\mathbf{b}$, respectively. Moreover, for $i \in [L]$ and $j \in [W] \triangleq \{1,\ldots, W\}$, we use $a_{i, j}$ and $b_{i, j}$ to denote the $j$-th element in the rows $a(i)$ and $b(i)$, respectively. Therefore, for $i \in [L]$, we have 
\begin{align}
a(i) = \big(a_{i,1}, a_{i,2},\ldots, a_{i, W}\big) \in \{0, 1\}^W\nonumber \\
b(i) = \big(b_{i,1}, b_{i,2},\ldots, b_{i, W}\big) \in \{0, 1\}^W. \nonumber
\end{align}
Now, consider a linear coding scheme that produces a parity bank $\mathbf{p}$ with $L'W$ bits arranged in an $L' \times W$ array such that for $i \in [L'] \triangleq \{1,\ldots, L'\}$, 
\begin{align}
p(i) &= \big(p_{i, 1},\ldots, p_{i,W}\big) = a(i) + b(i) \nonumber \\
&\triangleq \left(a_{i,1} + b_{i,1}, a_{i,1} + b_{i,1},\ldots, a_{i,1} + b_{i,1}\right). 
\end{align}
\end{example}
\begin{remark}
Figure~\ref{fig:example1} illustrates this coding scheme. Since the parity bank is based on those rows of the data banks that are indexed by the set $[L'] \subseteq [L]$, we also use the following concise notation to represent the encoding of the parity bank. 
$$
\mathbf{p} = \mathbf{a}([L']) +  \mathbf{b}([L']).
$$
In general, we can use any subset $\mathcal{S} = \{i_1, i_2,\ldots, i_{L'}\} \subseteq [L]$ comprising $L'$ rows of data banks to generate the parity bank $\mathbf{p}$. In this case, we have $\mathbf{p} = \mathbf{a}(\mathcal{S}) +  \mathbf{b}(\mathcal{S})$, or
\begin{align*}
p(l) = a(i_l) + b(i_l)~\text{for}~l \in [L'].
\end{align*}
%Figure~\ref{fig:example1_case2} illustrates the case with a generic set $\mathcal{S}$.% $ = [L - L'  + 1,\ldots, L]$.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[t!]
%\centering
%\begin{subfigure}[b]{0.48\linewidth}
%  \centering
%  \includegraphics[width=0.95\linewidth]{fig/example-inter-bank.pdf} 
%  \caption{{\color{red}Parity.}}
%  \label{fig:example1_case1}
%\end{subfigure}
%\begin{subfigure}[b]{0.48\linewidth}
%  \centering
%  \includegraphics[width=0.98\linewidth]{fig/example-inter-bank-2.pdf} 
%  \caption{{\color{red}Parity.}}
%  \label{fig:example1_case2}
%\end{subfigure}
%\caption{{\color{red}Design.}}
%\label{fig:example1}
%\end{figure}
\begin{figure}[t!]
\centering
  \includegraphics[width=0.45\linewidth]{fig/example-inter-bank.pdf} 
\caption{Notation of example parity design. {\color{red}ok?}}
\label{fig:example1}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{remark}
{\color{red} Note that we allow for the data banks and parity banks to have different sizes, \textit{i.e.} $L \neq L'$. This freedom in memory design can be utilized to reduce the storage overhead of parity banks based on the underlying application. The case when the size of a parity bank is smaller than a data bank, \textit{i.e.} $L' < L$, we say that the parity bank is a {\em shallow bank}. We note that it is reasonable assume the existence of shallow banks, especially in proprietary designs of integrated memories in a system on a chip (SoC).}
\end{remark}

\begin{remark}
\label{rem:design1}
Note that the size of shallow banks is a design choice which is controlled by the parameter $0 < \alpha \leq 1$. A small value of $\alpha$ corresponds to small storage overhead. However, $\alpha < 1$ ensures multiple access for only a subset of data elements (belonging to the encoded rows) from the data banks. The identity of the $L' = \alpha L$ rows from data banks that are encoded using the shallow parity banks depend on nature of access request being served by the memory system. In particular, in Section~\ref{sec:dynamicCoding} we discuss a dynamic coding approach that changes the encoded rows based on the detection of the regions of memory banks that receive a large number of access requests. For applications, where such sustained concentration of access patterns is not present, one can employ design with $\alpha = 1$, \textit{i.e.}, the parity banks have the same size as the data banks and all the elements of the data banks are stored in the encoded form in the array of banks. \Ethan{rewrite, esp. last sentence}
\end{remark}

\subsubsection{Degraded reads and their locality}
\label{sec:degraded}

Now let's focus on the application of redundant (encoded) data stored on an array of banks to improve the {\bf read} accesses to the original data elements by avoiding bank conflicts. Let's consider the coding scheme illustrated in Figure~\ref{fig:example1}, where the parity bank stores $\mathbf{p} = \mathbf{a}([L']) + \mathbf{b}([L'])$. Now, given two read requests $\{a(1), a(L)\}$, which would have led to a bank conflict (at the data bank $\mathbf{a}$) without the parity banks, can now be simultaneously served without any bank conflicts: 1) Serve the request $a(L)$ from the data bank $\mathbf{a}$, and 2) Download $b(1)$ and $p(1) = a(1) + b(1)$ from the data bank $\mathbf{b}$ and the parity bank to serve $a(1)$ by reconstructing $a(1) = b(1) + p(1)$. A read request which is served with the help of parity banks (the request for $a(1)$ in this case) is termed as {\em degraded read}. Each degraded read has a parameter {\em locality} associated with it which corresponds to the total number of banks that need to be accessed to serve it. In this case, the degraded read for $a(1)$ using $\mathbf{b}$ and $\mathbf{p}$ has locality  $2$.

%In order to further illustrate the notion of locality, let's consider a setup where we generate a parity bank $\mathbf{p}$ by combining three data banks $\mathbf{a}$, $\mathbf{b}$, and $\mathbf{c}$ as $\mathbf{p} = \mathbf{a} + \mathbf{b} + \mathbf{c}$. Now, a degraded read for $a(1)$ using the parity bank as $$a(1) = b(1) + c(1) + p(1) = b(1) + c(1) + \big(a(1) + b(1) + c(1)\big)$$
%has locality $3$ as the degraded read is served using three memory banks.

\subsection{Codes to emulate multi-port memory}
\label{sec:designs}

We will now describe the code designs proposed in this work to emulate multi-port memories. Among a large set of possible coding schemes, we focus on three specific coding schemes for this task. We believe that these three coding schemes strike a good balance among various quantitative parameters, including storage overhead, number of simultaneous read requests supported by the array of banks, and the locality associated with various degraded reads. Furthermore, these coding schemes respect the practical constraint of encoding across a small number of data banks. In particular, we focus on the setup with $8$ memory banks (the design scales with larger number of banks). This contrasts with the communications applications where encoding typically occurs with blocks of $1024$ or more information symbols. 

In the rest of this section, we present three code designs and discuss the number of simultaneous read requests supported by these designs in the best and worst case. We also summarize all the relevant parameters associated with these designs in Table~\ref{table:codedesigncomparison}.
%
%We discuss the design of the codes for creating extra accesses to memory in this 
%section. First we discuss the code designs explored during Phase I. Second, we discuss 
%specific execution strategies to efficiently implement the designs.\\
%In the following sub-sections, we discuss 3 designs for storing coded data.  
%Table~\ref{table:codedesigncomparison} compares these designs for various 
%parameters and associated costs.  
%\begin{table*}[t]
%\centering
%	\begin{tabular}{|m{1cm}|m{2 cm}|m{1cm}|m{1cm}|m{1cm}|m{1cm}|m{1cm}|}
%\hline
%Design & Max Read per bank & Max Write per bank & Locality & Rate & Memory 
%Overhead & Logical Complexity \\ \hline
%I & 4 & 2 & 2 & $2/5$ & 1.5 $\alpha$ & Low \\ \hline
%II & 5 & 2 & 2 & $2/5$ & 2.5 $\alpha$ & Medium \\ \hline
%III & 4 & 2 & 3 & $1/2$ & \text{      } $\alpha$ & Medium \\ \hline
%	\end{tabular}
%	\caption{Comparison of design with respect to the performance parameters 
%	and associated cost}
%	\label{table:codedesigncomparison}
%\end{table*}


%\begin{tiny}
%\begin{table}[t!]
%  \centering
%  \begin{tabular}{|c|c|c|c|c|c|c|}
%    \hline
%    \textbf{Design} & \textbf{Max reads} & \textbf{Max writes} & \textbf{Locality} & \textbf{Rate} & \textbf{Storage overhead} & \textbf{Logical complexity} \\
%    & \textbf{(per bank)} & \textbf{(per bank)} & & & & \\
%    \hline
%    \hline
%    I & 4 & 2 & 2 & $2/5$ & 1.5 $\alpha$ & Low \\ \hline
%II & 5 & 2 & 2 & $2/5$ & 2.5 $\alpha$ & Medium \\ \hline
%III & 4 & 2 & 3 & $1/2$ & \text{      } $\alpha$ & Medium \\ 
%\hline                                   
%  \end{tabular}
%	\caption{Comparison of the code designs with respect to the performance parameters and associated cost}
%	\label{table:codedesigncomparison}
%\end{table}
%\end{tiny}

\begin{comment}
\begin{table}[t!]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
   {\small Design} & {\small  Max reads} &{\small  Locality} & {\small  Rate} & {\small  Storage} & {\small  Logical } \\
    & {\small  (per bank)} & & &{\small  overhead} & {\small  complexity} \\
    \hline
    \hline
    {\small I} & {\small$4$ } & {\small$2$} & {\small ${2}/{5}$} & {\small $1.5\alpha$} & {\small Low} \\ \hline
{\small II} & {\small$5$}  & {\small$2$} & {\small ${2}/{5}$} & {\small $2.5\alpha$} & {\small Medium} \\ \hline
{\small III }& {\small$4$}  & {\small$3$} & {\small$1/2$} & {\small $\alpha$} & {\small Medium} \\ 
\hline                                   
  \end{tabular}
	\caption{Comparison of the code designs with respect to the performance parameters and associated cost. $\alpha$ is the fraction of storage overhead in comparison to the data bank. $\alpha = 1$ when size of parity bank is equal to size of data bank.}
	\label{table:codedesigncomparison}
\end{table}
\end{comment}

\begin{table}[ht!]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
   {\scriptsize Design} & {\scriptsize  Max reads} &{\scriptsize  Locality} & {\scriptsize  Rate} & {\scriptsize  Storage} & {\scriptsize  Logical } \\
    & {\scriptsize  (per bank)} & & {\scriptsize ($\alpha=1$)}&{\scriptsize  overhead} & {\scriptsize  complexity} \\
    \hline
    \hline
    {\scriptsize I} & {\scriptsize$4$} & {\scriptsize$2$} & {\scriptsize $\nicefrac{2}{5}$} & {\scriptsize $1.5\alpha$} & {\scriptsize Low} \\ \hline
%{\scriptsize II} & {\scriptsize$5$}  & {\scriptsize$2$} & {\scriptsize ${2}/{5}$} & {\scriptsize $2.5\alpha$} & {\scriptsize Medium} \\ \hline
{\scriptsize II} & {\scriptsize$5$}  & {\scriptsize$2$} & {\scriptsize $\nicefrac{2}{7}${\color{red}?}} & {\scriptsize $2.5\alpha$} & {\scriptsize Medium} \\ \hline
{\scriptsize III }& {\scriptsize$4$}  & {\scriptsize$3$} & {\scriptsize$\nicefrac{1}{2}$} & {\scriptsize $\alpha$} & {\scriptsize Medium} \\ 
\hline                                   
  \end{tabular}
	\caption{Comparison of the code designs with respect to the performance parameters and associated cost}
	\label{table:codedesigncomparison}
\end{table}


\subsubsection{Code Design I}
\label{sec:design1}

This code design is motivated from the concept of batch codes~\cite{batchcodes} which enables parallel access to the content stored in a large scale distributed storage system.  This design employs only inter-bank encoding across rows of data banks. 
%The coding scheme is illustrated in Figure~\ref{fig:design1}. 
The code design involves $8$ data banks $\{\mathbf{a}, \mathbf{b},\ldots, \mathbf{h}\}$ (each of size $L$) and $12$ shallow banks (each of size $L' = \alpha L$ for $0< \alpha \leq 1$). We partition the $8$ data banks into two disjoint groups consisting of $4$ banks each. The underlying coding scheme produces (shallow) parity banks by separately encoding data banks from the two groups. Thus, as shown in Figure~\ref{fig:design1}, the entire array of banks, including data banks and parity banks, can be viewed as partitioned into two disjoint code regions. For a specific choice of $\alpha$, the storage overhead of this design is $12\alpha L$ which amounts to the rate of the coding scheme being $$\frac{8L}{8L + 12\alpha L} = \frac{2}{2 + 3\alpha}.$$


We now analyze the number of simultaneous read requests that can be supported by this code design. \\
%This allows us to serve multiple accesses to the coded 
%region using the parity banks. With this scheme, we guarantee that any 4 read 
%requests to the coded region can be served at any given time. As shown in 
%figure~\ref{fig:design1}, 8 banks are divided into two regions.  Each region 
%consists of 4 banks. Each region has 6 parallel shallow  banks to store the 
%parity. The colored regions shown in the banks 1-8 are the coded region. These 
%regions are assumed to be of $\alpha $ fraction of the memory. \\

\noindent \textbf{Best case analysis:~}This code design achieves maximum 
performance when sequential accesses to the coded regions are issued. During the 
best case access, we can achieve up to $10$ parallel accesses to a particular coded region in one access cycle.
Consider the scenario when we receive accesses to the following $10$ rows:
\begin{align*}
&\left\{a(1),b(1),c(1),d(1),a(2),b(2),c(2),d(2),c(3),d(3)\right\} .
\end{align*}
Note that we can serve the read requests for the rows
$\{a(1),b(1),c(1),d(1)\}$ using the data bank $\mathbf{a}$ and the three parity banks storing $\{a(1)+b(1), b(1)+c(1),c(1)+d(1)\}$. 
The requests for $\{a(2),c(2),d(2)\}$ can be served by downloading $b(2)$ from the data bank $\mathbf{b}$ and $\{a(2)+d(2), b(2)+d(2),a(2)+c(2)\}$ from the respective parity banks storing these. Lastly, in the same memory clock cycle, we can serve the requests for $\{c(3), d(3)\}$ using the data banks $\mathbf{c}$ and $\mathbf{d}$.\\
%------------------------------
\begin{figure}[ht!]
\centering
	%\includegraphics[width=0.8\linewidth]{fig/designI.pdf}
	\includegraphics[width=1\linewidth]{fig/Code-Design-1.pdf}
	\caption{Code Design I}
	\label{fig:design1}
%\caption{Code Designs}
\end{figure} 
%------------------------------
\ignore{
%------------------------------
\begin{figure}[ht!]
\centering
\includegraphics[width=150mm,natwidth=610,natheight=642]{fig/result_design1.jpg}
\caption{ }
\label{fig:result_design1}
\end{figure}
%------------------------------
}
\noindent \textbf{Worst case analysis}: The code design under consideration (cf.~Figure~\ref{fig:design1}) falls off to $4$ access in 
a single memory clock cycle when there are non-sequential and non-consecutive access to the memory 
banks. For example, when we receive read requests for  
\begin{align*}
\{a(1), a(2), b(8), b(9), c(10),c(11), d(14), d(15)\}. 
\end{align*}
Since parity elements combining the data elements from these requested rows are not present in the parity banks, the underlying coding scheme does not provide any benefits. However, we still benefit from the prefetching mechanism discussed in Section~\ref{sec:prefetching}. The worst case number of reads per cycle is equal to the number of data banks. 
%In Figure~\ref{fig:result_design1} , we explore the worst case scenario when 
%the accesses are random. The results show that the queue build up for reads and 
%writes does fall back to no-coding scenario. This asserts that the worst case 
%scenario for a coding scheme performs similar to no-coding scheme.In the second 
%scheme, we augment the code storage by cross storing the codes from region 1 to 
%region 2 and vice-versa.We do this in addition to coding the consecutive memory 
%addresses in a bank. This provides two benefits, first it increases the overall 
%redundancy, and second it allows us to use the parity banks of the other region 
%in case the first region’s parity banks are in use. 
\ignore{
\begin{figure}[!ht]
\centering
\includegraphics[width=150mm,natwidth=610,natheight=642]{fig/result_design2.jpg}
\caption{ Comparison of Design II with No coding case }
\label{fig:result_design2}
\end{figure}
}
\subsubsection{Code Design II}
\label{sec:design2}

Figure~\ref{fig:design2} illustrates the second code design explored in this paper. Again, the $8$ data banks $\{\mathbf{a}, \mathbf{b},\ldots, \mathbf{h}\}$ are partitioned into two groups containing $4$ data banks each. These two groups are then associated with two code regions. This code design generates $9$ parity banks for $8$ data banks, where only the content stored on the data banks from the same region is combined to generate these parity elements. As evident from Figure~\ref{fig:design2}, this design employs both inter-bank and intra-bank encoding in order to generate the content to be stored on the parity banks. For example, the parity element $a(1) + a(L'+1)$ results from an intra-bank encoding operation. \Ethan{NO!} This code design differs from the previous code design (cf. Figure~\ref{fig:design1}) in terms of the size and arrangement parity banks. Even though $L' = \alpha L$ rows from each data bank are stored in a coded manner by generating parity elements, the parity banks are assumed to be storing $2\alpha L > L'$ rows. Furthermore, the parity-banks generated using intra-bank encoding from one code region are stored on the parity banks of another code region.

For a specific choice of $\alpha$, the storage overhead of this design is $20\alpha L$ which amounts to the rate of the coding scheme being $$\frac{8L}{8L + 20\alpha L} = \frac{2}{2 + 5\alpha}.$$ Note that this code design can support $5$ read accesses per data bank in a single memory clock cycle as opposed to $4$ read requests supported by the code design from Section~\ref{sec:design1}. However, this is made possible at the cost of extra storage overhead. Next, we discuss the performance of this code design in terms of the number of simultaneous read requests that can be served in the best and worst case.

%
%The second design, presented in figure 4, improves over first design by allowing 
%5 read accesses per bank per cycle. This design also divides banks into two 
%regions. The first region is
%Bank 1 to Bank 4 and 5 corresponding Parity banks. The two regions in figure 4 
%are upper 9 banks forming one region and lower 9 banks forming another. This 
%design allows intermix storage of parity among regions. The design uses 5 parity 
%banks per region. The data in this scheme is coded for both inter bank and 
%intra-bank. The intra-bank codes are stored in the alternate parity bank region. 
%This allows usage of parity banks from other region if they are available. \\
\begin{figure}[!ht]
%\centering
%\begin{minipage}[!t]{\linewidth}
	%\includegraphics[width=1\linewidth]{fig/designII.pdf}
	\includegraphics[width=1\linewidth]{fig/Code-Design-2.pdf}
	\caption{Code Design II}
	\label{fig:design2}
%\end{minipage}
\end{figure}

\noindent \textbf{Best case analysis:~} This code design achieves the best access performance when sequential accesses to the data banks are issued. In particular, this design can support up to $9$ read requests in a single memory clock cycle. Consider the scenario where we receive read requests for the following rows of the data banks. 
$$
\big\{a(1),b(1),c(1),d(1),a(2),b(2),c(2),d(2),a(3),b(3),c(3)\big\}
$$ Here, we can serve the requests for the rows $\{a(1), b(1), c(1), d(1)\}$ using the data bank $\mathbf{a}$ with the parity banks storing the parity elements $\{a(1) + b(1),b(1)+c(1),c(1)+d(1)\}$. Similarly, we can serve the requests for the rows $\{a(2),b(2),d(2)\}$ using the data bank $\mathbf{b}$ with the parity banks storing the parity elements $\{a(2)+d(2), b(2)+d(2)\}$. Lastly, the request for the rows $c(2)$ and $d(3)$ is served using the data banks $\mathbf{c}$ and $\mathbf{d}$.\\


\noindent \textbf{Worst case analysis:~}The code scheme can enable $5$ simultaneous accesses in a single memory clock cycle in the
worst case. These are non-sequential and non-consecutive accesses to the memory banks. For 
example, when the access pattern corresponds to the rows $\{a(1),b(6),c(9),d(15),e(20)\}$, we can simultaneously serve 
these $5$ read requests with the help of our coded memory. In order to better utilize the unused banks in this case, we can use the prefetching 
mechanisms (cf. Section~\ref{sec:prefetching}) to look ahead in the queue and proactively download elements from the unused banks for future accesses.


% This design employs both inter-bank and intra-bank encoding in order to generate the content to be stored on the parity banks. In order to illustrate another flexibility that can be utilized while designing the storage space for a memory system, even though this code design encodes $\alpha L$ rows from each data bank, the parity banks are assumed to be storing $2\alpha L$ rows.


\subsubsection{Code Design III}
The two code designs discussed so far have locality $2$, \textit{i.e.} we need to access $2$ memory banks to serve a read request with the help of parity symbols. The next design that we consider has locality $3$. This code design works with $9$ data bank $\{\mathbf{a}, \mathbf{b},\ldots, \mathbf{h}, \mathbf{z}\}$ and generates $9$ (shallow) parity banks. Figure~\ref{fig:design3} describes this design. As on can verify that this design relies on only inter-bank encoding to generate parity symbols. 
%The two designs discussed above achieve a rate of $2/5$. Here, we explore a code design which achieves a rate of $1/2$. 
%This design requires 9 data banks and 9 parity banks as shown in figure 5. It 
%also has a comparatively higher locality of 3. That is, it requires the memory 
%controller to "know" two out of three data elements to decode the third. 
The storage overhead of this design is $9\alpha L$ which corresponds to the rate of $\frac{1}{1 + \alpha}$. We note that this design possesses higher logical complexity because of increased locality. 

This design helps us support $4$ simultaneous read access per bank per memory clock cycle. As an example, the requests for the rows $\{a(1), a(2), a(3), a(4)\}$ can be satisfied as follows. The request for $a(1)$ can be served bu the data bank $\mathbf{a}$. The request for the row $\mathbf{a}(2)$ can be supported by using the data banks $\mathbf{b}$ and $\mathbf{c}$ along with the parity bank storing $a(2) + b(2) + c(2)$. Similarly, the data banks $\mathbf{d}$ and $\mathbf{g}$ along with parity bank storing $a(3) + d(3) + g(3)$ allows us to access $a(3)$. Lastly, we can serve the request for the row $a(4)$ by using the data banks $\mathbf{e}$ and $\mathbf{z}$ with the parity element $a(4) + e(4) + z(4)$.
\noindent \textbf{Best case analysis:~} Following the analysis similar to design I and II, the best case number of reads per cycle will be equal to sum of data bank and parity bank (18 reads per cycle in case of design III). 

\noindent \textbf{Worst case analysis:~} Similar to design I and design II, the number of reads per cycle is equal to the number of data banks (9 in case of design III). 
%The memory overhead here is less (just $\alpha$) compared to the previous designs. However, it possesses higher logical complexity because of increased locality. Example cases for this design are described below :
%\begin{itemize}
%
%	\item 4 reads for $a_0$: 1 read from $a_0$, 1 read from ($a_1$, $a_2$, 
%		$a_0$ + $a_1$ + $a_2$), 1 read from ($a_3$, $a_6$, $a_0$ + $a_3$ 
%		+ $a_6$), and the 4th read from ($a_4$, $a_8$, $a_0$ + $a_4$ + 
%		$a_8$).
%	\item 3 reads for $a_0$: 1 read from $a_0$, 1 read from ($a_3$, $a_6$, 
%		$a_0$ + $a_3$ + $a_6$), and the 3rd read from ($a_4$, $a_8$, 
%		$a_0$ + $a_4$ + $a_8$). \\
%	      1 read for $a_1$:  1 read from $a_1$.
%	\item 2 reads for $a_0$: 1 read from $a_0$ and the 2nd read from ($a_3$, 
%		$a_6$, $a_0$ + $a_3$ + $a_6$). \\
%	      2 reads for $a_1$: 1 read from $a_1$ and the 2nd read from ($a_4$, 
%	      $a_7$, $a_1$ + $a_4$ + $a_7$).
%	\item 2 reads for $a_0$: 1 read from $a_0$ and the 2nd read from ($a_3$, 
%		$a_6$, $a_0$ + $a_3$ + $a_6$). \\
%	      1 read for $a_1$: 1 read from $a_1$. \\
%	      1 read for $a_2$: 1 read from $a_2$.
%    \end{itemize}
%---------------------------------------
\begin{figure}[!ht]
	\centering
	\begin{minipage}[!t]{\linewidth}
		\includegraphics[width=\linewidth]{fig/Code-Design-3_9banks.pdf}
		\caption{Code Design III}
		\label{fig:design3}
	\end{minipage}
\end{figure}
%---------------------------------------

\begin{remark}
Note that the coding scheme in Figure~\ref{fig:design3} describes a system with $9$ data banks. However, we have set out to construct a memory system with $8$ data banks. It is straightforward to modify this code design to work with $8$ data banks $\{\mathbf{a}, \mathbf{b},\ldots, \mathbf{h}\}$. In particular, we can assume the data elements store in the data bank to be all $0$s and discard this bank. This results into the code design described in Figure~\ref{fig:design3_8}. Since we assume the elements of the discarded data bank $\mathbf{z}$ to be all $0$s, the resulting $9$ parity banks do not have any contribution from this bank. Note that the modified memory system has varying locality for degraded reads. Some degraded reads require accessing $3$ banks (e.g., accessing $a(1)$ using $b(1)$, $c(1)$ and $a(1) + b(1) + c(1)$) while other degraded reads have locality $3$ (e.g., accessing $g(1)$ using $h(1)$ and $g(1) + h(1)$). Note that the storage overhead of the modified design is the same as that of the design described in Figure~\ref{fig:design3}.
%Since most systems are implemented with number of banks as $2^n$ for some n. We present an 
%example of the code with 8 data banks in figure~\ref{fig:design3_8}. For using 8 data banks, 
%we drop the bank I. We also ignore the data from Bank I for constructing parity. So, three of 
%the parity banks have the locality of 2, while the rest of the parity banks have locality of 3.
% The new scheme for 8 data banks has 9 parity banks.
 \end{remark}
%---------------------------------------
\begin{figure}[!ht]
\centering
	\begin{minipage}[!t]{\linewidth}
		\includegraphics[width=\linewidth]{fig/Code-Design-3_8banks.pdf}
		\caption{Code Design III with 8 data banks}
		\label{fig:design3_8}
	\end{minipage}
\end{figure}
%---------------------------------------

\Ankit{What about the best case vs worst case analysis for this design??}

\begin{comment}
Since the locality is 3 here in this design, i.e. , each parity is made up of combination of 3 data banks, we need to make sure that all three requests are in one line to be able to use the parity bank. 
For example parity bank 0 contains A+B+C. So, the following scenarios arise:
\begin{itemize}
	\item {\em Scenario I}: 1st request of A and 1st request of B are in same row. Then, we can search for a request in the same row for bank C by doing a look ahead. 
	\item {\em Scenario II}: 1st request of A and 1st request of C are in same row. Then, we can search for a request in the same row for bank B by doing a look ahead. 
	\item {\em Scenario III}: 1st request of B and 1st request of C are in same row. Then, we can search for a request in the same row for bank A by doing a look ahead. 
\end{itemize}
So, the simple pseudo code for doing this would be :\\
\begin{verbatim}
for each data bank 
    for each auxiliary bank1 of data bank
            Look ahead in auxiliary bank2 and check if 3 request in a row.
        end
    end
\end{verbatim}
Example: - \\
For {\bf data bank} to be {\bf A} \\
{\bf auxiliary bank1} goes from [B C D G A E] \\
{\bf auxiliary bank2} goes from [C B G D E A] \\
  The element A is just there in {\bf auxiliary bank1} and {\bf auxiliary bank2} to maintain the symmetry because A + E has locality of 2.
\end{comment}
